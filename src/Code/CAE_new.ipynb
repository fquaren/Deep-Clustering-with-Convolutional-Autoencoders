{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "#creo lista di nomi \n",
    "directories = ['data/train/', \n",
    "               'data/val/', \n",
    "               'data/test/']\n",
    "\n",
    "train_file_names = [f for f in listdir(directories[0]) if isfile(join(directories[0], f))]\n",
    "val_file_names = [f for f in listdir(directories[1]) if isfile(join(directories[1], f))]\n",
    "test_file_names = [f for f in listdir(directories[2]) if isfile(join(directories[2], f))]\n",
    "\n",
    "_file_names = [train_file_names, val_file_names, test_file_names] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numero immagini per categoria\n",
    "scans = ['CT','MRI','PET']\n",
    "numbers=[]\n",
    "minimi=[]\n",
    "\n",
    "for directory in directories:    \n",
    "    for scan in scans:\n",
    "        a = len([f for f in listdir(directory) if f[:2]==scan[:2]])\n",
    "        #print('Numbero di immagini', scan, 'in', directory,':', a)\n",
    "        numbers.append(a)\n",
    "    minimi.append(min(numbers))\n",
    "\n",
    "#print(minimi)\n",
    "#=> è sempre la PET che ha il numero minore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo la lista di file bilanciata: n.b  la percentuale viene mantenuta\n",
    "train_final_file_names=[]\n",
    "val_final_file_names=[]\n",
    "test_final_file_names=[]\n",
    "_final_file_names = [train_final_file_names, val_final_file_names, test_final_file_names] \n",
    "\n",
    "l=[]\n",
    "for directory,minimo,name in zip(directories, minimi,_final_file_names):    \n",
    "    for scan in scans:\n",
    "        l = [f for f in listdir(directory) if f[:2]==scan[:2]]\n",
    "        random.shuffle(l)\n",
    "        l = l[:minimo]\n",
    "        name.extend(l) #estendo la lista (don't append)\n",
    "        \n",
    "# How I cicled ^^^\n",
    "\n",
    "#    minimo |\n",
    "#    name   |\n",
    "#    train  | val | test\n",
    "# \n",
    "# CT    ... | ... | ...\n",
    "# MRI   ... | ... | ...\n",
    "# PET   ... | ... | ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DATASET\")\n",
    "print(\"Training\", len(train_final_file_names), \", Validation:\", len(val_final_file_names) ,\", Test:\", len(test_final_file_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converto le immagini in tensori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteAndArrayImages(path):\n",
    "    x = io.imread(path[random.randint(0,10)])\n",
    "    x = cv2.resize(x, dsize=(128,128))\n",
    "    \n",
    "    for img in path[1:]:\n",
    "        img = io.imread(img)\n",
    "        img = cv2.resize(img, dsize=(128,128))\n",
    "        x = np.dstack((x,img))\n",
    "    x = np.rollaxis(x,-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#paths per leggere le immagini\n",
    "train_paths=[]\n",
    "val_paths=[]\n",
    "test_paths=[]\n",
    "_paths=[train_paths,val_paths,test_paths]\n",
    "\n",
    "for path,name,directory in zip(_paths,_final_file_names,directories):\n",
    "    for f in name:\n",
    "        path.append(directory+f)\n",
    "\n",
    "#leggo le immagini e le stacco una sopra l'altra\n",
    "x_train = WriteAndArrayImages(train_paths)\n",
    "x_val = WriteAndArrayImages(val_paths)\n",
    "x_test = WriteAndArrayImages(test_paths)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "#plot images from each dataset\n",
    "f, axarr = plt.subplots(1,3,figsize=(12, 12))\n",
    "axarr[0].imshow(x_train[random.randint(0,100)], cmap=plt.cm.gray)\n",
    "axarr[1].imshow(x_val[random.randint(0,100)], cmap=plt.cm.gray)\n",
    "axarr[2].imshow(x_test[random.randint(0,100)], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeLabels(_name_files):\n",
    "    y=[]\n",
    "    for text in _name_files:\n",
    "        fileNameOnly = text[:text.find(ext)]\n",
    "        y.append(''.join([i for i in fileNameOnly if not i.isdigit()]))\n",
    "    for i, item in enumerate(y):\n",
    "        if item == 'CT':\n",
    "            y[i] = 0\n",
    "        elif item == 'MRI':\n",
    "            y[i] = 1\n",
    "        else: y[i] = 2    \n",
    "    y = np.concatenate((y,))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estensione immagini\n",
    "ext = '.png'\n",
    "\n",
    "#costruisco le lables\n",
    "y_train = MakeLabels(_final_file_names[0])\n",
    "y_val = MakeLabels(_final_file_names[1])\n",
    "y_test = MakeLabels(_final_file_names[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check\n",
    "X = [x_train, x_val, x_test]\n",
    "Y = [y_train, y_val, y_test]\n",
    "\n",
    "for x,y in zip(X,Y):\n",
    "    if len(x) != len(y):\n",
    "        print(len(x))\n",
    "        print(len(y))\n",
    "        print('Error! La lunghezza delle liste non combacia!')\n",
    "    else: \n",
    "        print('Ok, le lunghezze combaciano con le X')\n",
    "\n",
    "#controlla numero di cluster (expected 3)\n",
    "n_clusters = len(np.unique(y))\n",
    "print('Clusters:', n_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder Model \n",
    "N.B. Execute only the model you want to train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, Conv2DTranspose\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoderConv2D_1(input_shape=(128, 128, 1), filters=[32, 64, 128, 256, 3]):\n",
    "    input_img = Input(shape=input_shape)\n",
    "    if input_shape[0] % 8 == 0:\n",
    "        pad3 = 'same'\n",
    "    else:\n",
    "        pad3 = 'valid'\n",
    "    x = Conv2D(filters[0], 5, strides=2, padding='same', activation='relu', name='conv1', input_shape=input_shape)(input_img)\n",
    "\n",
    "    x = Conv2D(filters[1], 5, strides=2, padding='same', activation='relu', name='conv2')(x)\n",
    "\n",
    "    x = Conv2D(filters[2], 3, strides=2, padding='same', activation='relu', name='conv3')(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    encoded = Dense(units=filters[3], name='embedding')(x)\n",
    "    \n",
    "    y = Dense(units=filters[4], name='output_to_cluster')(encoded)\n",
    "    \n",
    "    x = Dense(units=filters[2]*int(input_shape[0]/8)*int(input_shape[0]/8), activation='relu')(encoded)\n",
    "\n",
    "    x = Reshape((int(input_shape[0]/8), int(input_shape[0]/8), filters[2]))(x)\n",
    "    \n",
    "    x = Conv2DTranspose(filters[1], 3, strides=2, padding='same', activation='relu', name='deconv3')(x)\n",
    "\n",
    "    x = Conv2DTranspose(filters[0], 5, strides=2, padding='same', activation='relu', name='deconv2')(x)\n",
    "\n",
    "    decoded = Conv2DTranspose(input_shape[2], 5, strides=2, padding='same', name='deconv1')(x)\n",
    "    \n",
    "    return Model(inputs=input_img, outputs=decoded, name='AE'), Model(inputs=input_img, outputs=y, name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, encoder = autoencoderConv2D_1()\n",
    "\n",
    "print('ENCODER')\n",
    "encoder.summary()\n",
    "\n",
    "print('AUTOENCODER')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape Arrays for AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this function for reshaping arrays for CAE\n",
    "def ReshapeCAE(array):\n",
    "    array = array.reshape(array.shape + (1,))\n",
    "    array = array/255.\n",
    "    return array\n",
    "\n",
    "x_train = ReshapeCAE(x_train)\n",
    "x_val = ReshapeCAE(x_val)\n",
    "x_test = ReshapeCAE(x_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine.topology import Layer\n",
    "\n",
    "class ClusteringLayer(Layer):\n",
    "    \"\"\"\n",
    "    Clustering layer converts input sample (feature) to soft label, i.e. a vector that represents the probability of the\n",
    "    sample belonging to each cluster. The probability is calculated with student's t-distribution.\n",
    "\n",
    "    # Example\n",
    "    ```\n",
    "        model.add(ClusteringLayer(n_clusters=10))\n",
    "    ```\n",
    "    # Arguments\n",
    "        n_clusters: number of clusters.\n",
    "        weights: list of Numpy array with shape `(n_clusters, n_features)` witch represents the initial cluster centers.\n",
    "        alpha: degrees of freedom parameter in Student's t-distribution. Default to 1.0.\n",
    "    # Input shape\n",
    "        2D tensor with shape: `(n_samples, n_features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(n_samples, n_clusters)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
    "        self.clusters = self.add_weight(shape=(self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        \"\"\" student t-distribution, as same as used in t-SNE algorithm.\n",
    "         Measure the similarity between embedded point z_i and centroid µ_j.\n",
    "                 q_ij = 1/(1+dist(x_i, µ_j)^2), then normalize it.\n",
    "                 q_ij can be interpreted as the probability of assigning sample i to cluster j.\n",
    "                 (i.e., a soft assignment)\n",
    "        Arguments:\n",
    "            inputs: the variable containing data, shape=(n_samples, n_features)\n",
    "        Return:\n",
    "            q: student's t-distribution, or soft labels for each sample. shape=(n_samples, n_clusters)\n",
    "        \"\"\"\n",
    "        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "        q **= (self.alpha + 1.0) / 2.0\n",
    "        q = K.transpose(K.transpose(q) / K.sum(q, axis=1)) # Make sure each sample's 10 values add up to 1.\n",
    "        return q\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return input_shape[0], self.n_clusters\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'n_clusters': self.n_clusters}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters (to edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import VarianceScaling\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "init = VarianceScaling(scale=1. / 3., mode='fan_in', distribution='uniform')\n",
    "\n",
    "pretrain_epochs = 50 #####\n",
    "batch_size = 16 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir results\n",
    "save_dir = './results'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.fit(x_train, \n",
    "                x_train, \n",
    "                batch_size=batch_size, \n",
    "                epochs=pretrain_epochs, \n",
    "                validation_data=(x_val, x_val),\n",
    "                #callbacks=[TensorBoard(log_dir='/tmp/autoencoder')]\n",
    "               )\n",
    "\n",
    "autoencoder.save_weights(save_dir+'/conv_ae_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights(save_dir+'/conv_ae_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorboard --logdir=/tmp/autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot train and validation loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot train and validation loss of pretraining\n",
    "plt.plot(autoencoder.history.history['loss'])\n",
    "plt.plot(autoencoder.history.history['val_loss'])\n",
    "plt.title('AE loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show prediction after pretraining CAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict images and display\n",
    "\n",
    "directories = ['data/train/', \n",
    "               'data/val/', \n",
    "               'data/test/']\n",
    "\n",
    "scans=['CT','MRI','PET']\n",
    "\n",
    "def PickListImagesPerType(directory,scan):\n",
    "    names = [f for f in listdir(directory) if f[:2]==scan[:2]]\n",
    "    return names\n",
    "\n",
    "def PickOneImage(names,directory,n):\n",
    "    image = io.imread(directory+names[n])\n",
    "    image = cv2.resize(image, dsize=(128,128))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image layer to display (change this to display different images and respective decoded ones)\n",
    "n = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORIGINAL IMAGES\n",
    "#pick one image per type of scan\n",
    "imgsCT = PickOneImage(PickListImagesPerType(directories[0],scans[0]),directories[0],n)\n",
    "imgsMRI = PickOneImage(PickListImagesPerType(directories[0],scans[1]),directories[0],n)\n",
    "imgsPET = PickOneImage(PickListImagesPerType(directories[0],scans[2]),directories[0],n)\n",
    "\n",
    "#DECODED IMAGES\n",
    "#costruisco la lista di immagini da decodificare\n",
    "listaCT=[]\n",
    "for f in PickListImagesPerType(directories[0],scans[0]): \n",
    "    listaCT.append(join(directories[0], f))\n",
    "\n",
    "listaMRI=[]\n",
    "for f in PickListImagesPerType(directories[0],scans[1]): \n",
    "    listaMRI.append(join(directories[0], f))\n",
    "    \n",
    "listaPET=[]\n",
    "for f in PickListImagesPerType(directories[0],scans[2]): \n",
    "    listaPET.append(join(directories[0], f))\n",
    "\n",
    "#decode images per type of scan\n",
    "decoded_imgsCT = autoencoder.predict(ReshapeCAE(WriteAndArrayImages(listaCT)))\n",
    "decoded_imgsMRI = autoencoder.predict(ReshapeCAE(WriteAndArrayImages(listaMRI)))\n",
    "decoded_imgsPET = autoencoder.predict(ReshapeCAE(WriteAndArrayImages(listaPET)))\n",
    "\n",
    "#select one decoded image and make in plottable\n",
    "decoded_imgCT = decoded_imgsCT[n].reshape(128,128)\n",
    "decoded_imgMRI = decoded_imgsMRI[n].reshape(128,128)\n",
    "decoded_imgPET = decoded_imgsPET[n].reshape(128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(13,10))\n",
    "\n",
    "#plot images\n",
    "ax = plt.subplot(2,3,1)\n",
    "plt.imshow(imgsCT)\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "ax = plt.subplot(2,3,2)\n",
    "plt.imshow(imgsMRI)\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "ax = plt.subplot(2,3,3)\n",
    "plt.imshow(imgsPET)\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "ax = plt.subplot(2,3,4)\n",
    "plt.imshow(decoded_imgCT)\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "ax = plt.subplot(2,3,5)\n",
    "plt.imshow(decoded_imgMRI)\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "ax = plt.subplot(2,3,6)\n",
    "plt.imshow(decoded_imgPET)\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2, hspace=-0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCEC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine.topology import InputSpec\n",
    "\n",
    "clustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder.output)\n",
    "model = Model(inputs=encoder.input, outputs=[clustering_layer, autoencoder.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "\n",
    "plot_model(model, to_file='DCEC_model.png', show_shapes=True)\n",
    "Image(filename='DCEC_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inizialize cluster centers using k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import metrics as metrics\n",
    "\n",
    "feature_model = Model(input=encoder.input, outputs=encoder.get_layer(name='output_to_cluster').output)\n",
    "features = feature_model.predict(x_train)\n",
    "km = KMeans(n_clusters=n_clusters)\n",
    "\n",
    "features = np.reshape(features, newshape=(features.shape[0], -1))\n",
    "y_pred = km.fit_predict(features)\n",
    "print('acc=', metrics.acc(y_train, y_pred), 'nmi=', metrics.nmi(y_train, y_pred), 'ari=', metrics.ari(y_train, y_pred))\n",
    "\n",
    "y_pred_last = np.copy(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=['kld', 'mse'], loss_weights=[0.1, 1], optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_distribution(q):\n",
    "    weight = q ** 2 / q.sum(0)\n",
    "    return (weight.T / weight.sum(1)).T\n",
    "\n",
    "#for plotting\n",
    "lista_train_losses = [[],[],[]]\n",
    "lista_val_losses = [[],[],[]]\n",
    "iterazione=[]\n",
    "\n",
    "train_loss = [0,0,0]\n",
    "val_loss = [0,0,0]\n",
    "index = 0\n",
    "maxiter = 100\n",
    "update_interval = 1\n",
    "train_index_array = np.arange(x_train.shape[0])\n",
    "val_index_array = np.arange(x_val.shape[0])\n",
    "\n",
    "tol = 0.001 # tolerance threshold to stop training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metrics\n",
    "from IPython.core.debugger import set_trace\n",
    "#set_trace()\n",
    "\n",
    "\n",
    "for ite in range(int(maxiter)):\n",
    "    if ite % update_interval == 0:\n",
    "        q, _ = model.predict(x_train, verbose=0)\n",
    "        p = target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "        # evaluate the clustering performance\n",
    "        y_pred = q.argmax(1)\n",
    "        if y_train is not None:\n",
    "            acc = np.round(metrics.acc(y_train, y_pred), 5)\n",
    "            nmi = np.round(metrics.nmi(y_train, y_pred), 5)\n",
    "            ari = np.round(metrics.ari(y_train, y_pred), 5)\n",
    "            train_loss = np.round(train_loss, 5)\n",
    "            val_loss = np.round(val_loss, 5)\n",
    "            print('Iter', ite, ': Acc', acc, ', nmi', nmi, ', ari', ari, '; train_loss=', train_loss, ';val_loss=', val_loss) \n",
    "\n",
    "        # check stop criterion\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print('delta_label ', delta_label, '< tol ', tol)\n",
    "            print('Reached tolerance threshold. Stopping training.')\n",
    "            break\n",
    "    \n",
    "    # train on batch\n",
    "    idx_train = train_index_array[index * batch_size: min((index+1) * batch_size, x_train.shape[0])]\n",
    "    train_loss = model.train_on_batch(x=x_train[idx_train], y=[p[idx_train], x_train[idx_train]])\n",
    "    lista_train_losses[0].append(train_loss[0])\n",
    "    lista_train_losses[1].append(train_loss[1])\n",
    "    lista_train_losses[2].append(train_loss[2])\n",
    "    \n",
    "    idx_val = val_index_array[index * batch_size: min((index+1) * batch_size, x_val.shape[0])]\n",
    "    val_loss = model.test_on_batch(x=x_val[idx_val], y=[p[idx_val], x_val[idx_val]])\n",
    "    lista_val_losses[0].append(val_loss[0])\n",
    "    lista_val_losses[1].append(val_loss[1])\n",
    "    lista_val_losses[2].append(val_loss[2])\n",
    "    \n",
    "    index = index + 1 if (index + 1) * batch_size <= x_train.shape[0] else 0\n",
    "    \n",
    "    iterazione.append(ite)\n",
    "    \n",
    "\n",
    "# save the trained model\n",
    "print('saving model to:', save_dir + '/dcec_model_final.h5')\n",
    "model.save_weights(save_dir + '/dcec_model_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot DCEC train and validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "plt.subplot(1,3,1)\n",
    "x1=iterazione\n",
    "y1=lista_train_losses[0]\n",
    "y2=lista_val_losses[0]\n",
    "plt.plot(x1,y1)\n",
    "plt.plot(x1,y2)\n",
    "plt.title('L')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "x1=iterazione\n",
    "y1=lista_train_losses[1]\n",
    "y2=lista_val_losses[1]\n",
    "plt.plot(x1,y1)\n",
    "plt.plot(x1,y2)\n",
    "plt.title('Lr')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "x1=iterazione\n",
    "y1=lista_train_losses[2]\n",
    "y2=lista_val_losses[2]\n",
    "plt.plot(x1,y1)\n",
    "plt.plot(x1,y2)\n",
    "plt.title('Lc')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evaluation on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, _ = model.predict(x_test, verbose=0)\n",
    "p = target_distribution(q) \n",
    "\n",
    "test_loss = model.fit(x=x_test, y=[p, x_test])\n",
    "print(' Acc', acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show prediction after pretraining DCEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image layer to display (change this to display different images and respective decoded ones)\n",
    "n = 5 \n",
    "\n",
    "#ORIGINAL IMAGES\n",
    "#pick one image per type of scan\n",
    "imgsCT = PickOneImage(PickListImagesPerType(directories[2],scans[0]),directories[2],n)\n",
    "imgsMRI = PickOneImage(PickListImagesPerType(directories[2],scans[1]),directories[2],n)\n",
    "imgsPET = PickOneImage(PickListImagesPerType(directories[2],scans[2]),directories[2],n)\n",
    "\n",
    "#DECODED IMAGES\n",
    "#costruisco la lista di immagini da decodificare\n",
    "listaCT=[]\n",
    "for f in PickListImagesPerType(directories[2],scans[0]): \n",
    "    listaCT.append(join(directories[2], f))\n",
    "\n",
    "listaMRI=[]\n",
    "for f in PickListImagesPerType(directories[2],scans[1]): \n",
    "    listaMRI.append(join(directories[2], f))\n",
    "    \n",
    "listaPET=[]\n",
    "for f in PickListImagesPerType(directories[2],scans[2]): \n",
    "    listaPET.append(join(directories[2], f))\n",
    "\n",
    "#decode images per type of scan\n",
    "decoded_imgsCT = model.predict(ReshapeCAE(WriteAndArrayImages(listaCT)))[1]\n",
    "decoded_imgsMRI = model.predict(ReshapeCAE(WriteAndArrayImages(listaMRI)))[1]\n",
    "decoded_imgsPET = model.predict(ReshapeCAE(WriteAndArrayImages(listaPET)))[1]\n",
    "\n",
    "#select one decoded image and make in plottable\n",
    "decoded_imgCT = decoded_imgsCT[n].reshape(128,128)\n",
    "decoded_imgMRI = decoded_imgsMRI[n].reshape(128,128)\n",
    "decoded_imgPET = decoded_imgsPET[n].reshape(128,128)\n",
    "\n",
    "#plot images\n",
    "ax = plt.subplot(2,3,1)\n",
    "plt.imshow(imgsCT)\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "ax = plt.subplot(2,3,2)\n",
    "plt.imshow(imgsMRI)\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "ax = plt.subplot(2,3,3)\n",
    "plt.imshow(imgsPET)\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "ax = plt.subplot(2,3,4)\n",
    "plt.imshow(decoded_imgCT)\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "ax = plt.subplot(2,3,5)\n",
    "plt.imshow(decoded_imgMRI)\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "\n",
    "ax = plt.subplot(2,3,6)\n",
    "plt.imshow(decoded_imgPET)\n",
    "plt.gray()\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_model.predict(x_train)\n",
    "y_pred = km.fit_predict(features)\n",
    "plt.scatter(features[:,0], features[:,1], c=y_pred, s=50, cmap='brg')\n",
    "centers = km.cluster_centers_\n",
    "plt.scatter(centers[:,0], centers[:,1], c='black', s=200, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_model.predict(x_test)\n",
    "y_pred = km.fit_predict(features)\n",
    "plt.scatter(features[:,0], features[:,1], c=y_pred, s=50, cmap='brg')\n",
    "centers = km.cluster_centers_\n",
    "plt.scatter(centers[:,0], centers[:,1], c='black', s=200, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(font_scale=3)\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix([int(i) for i in y_test], y_pred)\n",
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", annot_kws={\"size\": 20});\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Clustering label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.linear_assignment_ import linear_assignment\n",
    "\n",
    "y_true = y.astype(np.int64)\n",
    "D = max(y_pred.max(), y_true.max()) + 1\n",
    "w = np.zeros((D, D), dtype=np.int64)\n",
    "# Confusion matrix.\n",
    "for i in range(y_pred.size):\n",
    "    w[y_pred[i], y_true[i]] += 1\n",
    "ind = linear_assignment(-w)\n",
    "\n",
    "sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
